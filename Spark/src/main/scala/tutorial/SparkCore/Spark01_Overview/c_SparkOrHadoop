Hadoop的MR框架和Spark框架都是数据处理框架，那么我们在使用时如何选择呢？

	Hadoop MapReduce由于其设计初衷并不是为了满足循环迭代式数据流处理，因此在多并行运行的数据可复用场景（如：机器学习、图挖掘算法、交互式数据挖掘算法）中存在诸多计算效率等问题。所以Spark应运而生，Spark就是在传统的MapReduce 计算框架的基础上，利用其计算过程的优化，从而大大加快了数据分析、挖掘的运行和读写速度，并将计算单元缩小到更适合并行计算和重复使用的RDD计算模型。
	机器学习中ALS、凸优化梯度下降等。这些都需要基于数据集或者数据集的衍生数据反复查询反复操作。MR这种模式不太合适，即使多MR串行处理，性能和时间也是一个问题。数据的共享依赖于磁盘。另外一种是交互式数据挖掘，MR显然不擅长。而Spark所基于的scala语言恰恰擅长函数的处理。
	Spark是一个分布式数据快速分析项目。它的核心技术是弹性分布式数据集（Resilient Distributed Datasets），提供了比MapReduce丰富的模型，可以快速在内存中对数据集进行多次迭代，来支持复杂的数据挖掘算法和图形计算算法。
	Spark和Hadoop的根本差异是多个作业之间的数据通信问题 : Spark多个作业之间数据通信是基于内存，而Hadoop是基于磁盘。
	Spark Task的启动时间快。Spark采用fork线程的方式，而Hadoop采用创建新的进程的方式。
	Spark只有在shuffle的时候将数据写入磁盘，而Hadoop中多个MR作业之间的数据交互都要依赖于磁盘交互
	Spark的缓存机制比HDFS的缓存机制高效。

经过上面的比较，我们可以看出在绝大多数的数据计算场景中，Spark确实会比MapReduce更有优势。但是Spark是基于内存的，所以在实际的生产环境中，由于内存的限制，可能会由于内存资源不够导致Job执行失败，此时，MapReduce其实是一个更好的选择，所以Spark并不能完全替代MR。

Hadoop 1.x
    1.NameNode是单点操作，容易出现单点故障，制约了HDFS的发展
    2.NameNode的内存限制影响了HDFS的发展
    3.MapReduce是一种基于数据集的工作模式，面向数据，这种工作模式一般是从存储上加载数据集，然后操作数据，最后写入物理存储设备，数据更多面临的是一次性的处理，所以初衷是单一计算，不支持迭代计算。
    4.资源调度和任务调度耦合在一起，无法扩展，所以Hadoop1.x就只能支持MR计算框架。
    JobTracker->(TaskTracker),(TaskTracker)

Hadoop 2.x
    1.此版本支持NameNode高可用
    2.支持Yarn资源调度框架，只做资源调度，不进行任务的调度
    2.MR框架只做任务调度，可插拔，所以扩展性非常强
    ResourceManager->{NodeManager[Container(MRAppMaster)]},{NodeManager[Container(MRTask)]}

为什么选择Spark：
Spark基于内存，意味着多个作业之间的数据通信问题的解决发生了根本性的变化
基于Scala开发的，所以天生支持函数式编程，支持迭代计算
Hadoop中MR计算模型非常简单，只有Map和Reduce，导致很多逻辑需要进行拆分，Spark提供了丰富的计算模型，通过模型的组合实现业务非常容易。