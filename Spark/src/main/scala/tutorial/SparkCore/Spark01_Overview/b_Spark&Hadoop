在之前的学习中，Hadoop的MapReduce是大家广为熟知的计算框架，那为什么咱们还要学习新的计算框架Spark呢，这里就不得不提到Spark和Hadoop的关系。

首先从时间节点上来看:
	Hadoop
	2006年1月，Doug Cutting加入Yahoo，领导Hadoop的开发
	2008年1月，Hadoop成为Apache顶级项目
	2011年1.0正式发布
	2012年3月稳定版发布
	2013年10月发布2.X (Yarn)版本
	Spark
	2009年，Spark诞生于伯克利大学的AMPLab实验室
	2010年，伯克利大学正式开源了Spark项目
	2013年6月，Spark成为了Apache基金会下的项目
	2014年2月，Spark以飞快的速度成为了Apache的顶级项目
	2015年至今，Spark变得愈发火爆，大量的国内公司开始重点部署或者使用Spark

然后我们再从功能上来看:
	Hadoop
	Hadoop是由java语言编写的，在分布式服务器集群上存储海量数据并运行分布式分析应用的开源框架
	作为Hadoop分布式文件系统，HDFS处于Hadoop生态圈的最下层，存储着所有的数据，支持着Hadoop的所有服务。它的理论基础源于Google的TheGoogleFileSystem这篇论文，它是GFS的开源实现。
	MapReduce是一种编程模型，Hadoop根据Google的MapReduce论文将其实现，作为Hadoop的分布式计算模型，是Hadoop的核心。基于这个框架，分布式并行程序的编写变得异常简单。综合了HDFS的分布式存储和MapReduce的分布式计算，Hadoop在处理海量数据时，性能横向扩展变得非常容易。
	HBase是对Google的Bigtable的开源实现，但又和Bigtable存在许多不同之处。HBase是一个基于HDFS的分布式数据库，擅长实时地随机读/写超大规模数据集。它也是Hadoop非常重要的组件。
	Spark
	Spark是一种由Scala语言开发的快速、通用、可扩展的大数据分析引擎
	Spark Core中提供了Spark最基础与最核心的功能
	Spark SQL是Spark用来操作结构化数据的组件。通过Spark SQL，用户可以使用SQL或者Apache Hive版本的SQL方言（HQL）来查询数据。
	Spark Streaming是Spark平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。

由上面的信息可以获知，Spark出现的时间相对较晚，并且主要功能主要是用于数据计算，所以其实Spark一直被认为是Hadoop MR框架的升级版。
